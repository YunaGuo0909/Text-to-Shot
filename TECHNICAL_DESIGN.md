# Technical Design: AI-Driven Storyboard Generation

## 1. System Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    STORYBOARD GENERATION PIPELINE                        â”‚
â”‚                                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  Script   â”‚â”€â–¶â”‚Shot Decomposerâ”‚â”€â–¶â”‚ Shot-Level  â”‚â”€â–¶â”‚ Camera   â”‚â”€â–¶â”‚Boardâ”‚â”‚
â”‚  â”‚  Input    â”‚  â”‚ (LLM-based)  â”‚  â”‚ Generator   â”‚  â”‚Trajectoryâ”‚  â”‚Renderâ”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”˜â”‚
â”‚                       â”‚                 â”‚               â”‚           â”‚    â”‚
â”‚                  Shot prompts      Per-shot 3D    Keyframeâ†’     Panels  â”‚
â”‚                 + shot types     configurations   Spline path  + paths  â”‚
â”‚                 + camera motion                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 2. Module Design

### Module 1: Shot Decomposer (æ–°å¢æ¨¡å—)

**ç›®æ ‡**: å°†ä¸€æ®µå®Œæ•´çš„åœºæ™¯æè¿°è‡ªåŠ¨åˆ†è§£ä¸ºå¤šä¸ªé•œå¤´çº§åˆ«çš„æç¤ºè¯ã€‚

**æ–¹æ³•**: ä½¿ç”¨ LLM (å¦‚ GPT-4 / open-source LLM) è¿›è¡Œå‰§æœ¬åˆ†æï¼š
- è¾“å…¥: åœºæ™¯æè¿°æ–‡æœ¬ (e.g., "Two people meet at a cafe. Person A waves and walks toward Person B. They shake hands and sit down together.")
- è¾“å‡º: ç»“æ„åŒ–çš„é•œå¤´åˆ—è¡¨ï¼Œæ¯ä¸ªé•œå¤´åŒ…å«ï¼š
  - `shot_description`: é•œå¤´æè¿° (e.g., "Person A waves at Person B")
  - `shot_type`: é•œå¤´ç±»å‹ (close-up / medium / wide / over-shoulder)
  - `shot_index`: é•œå¤´é¡ºåºç¼–å·
  - `duration_hint`: é¢„ä¼°æ—¶é•¿æç¤º
  - `camera_motion`: **é•œå¤´è¿åŠ¨ç±»å‹** (static / dolly-in / dolly-out / pan-left / pan-right / track / crane-up / crane-down)

**Prompt Engineering ç¤ºä¾‹**:
```
You are a professional film storyboard artist. Given a scene description,
decompose it into a sequence of cinematic shots. For each shot, specify:
1. A concise action description for two characters (A and B)
2. The recommended shot type (close-up, medium-shot, wide-shot, over-the-shoulder)
3. The camera motion (static, dolly-in, dolly-out, pan-left, pan-right, track, crane-up, crane-down)
4. The shot order

Scene: "{scene_description}"

Output as JSON array.
```

### Module 2: Shot-Level Generator (åŸºäºåŸè®ºæ–‡æ¨¡å‹æ‰©å±•)

**åŸºç¡€**: ç›´æ¥å¤ç”¨/å¾®è°ƒåŸè®ºæ–‡çš„ Joint Character-Camera Diffusion Model

**æ‰©å±•ç‚¹**:

#### 2a. Shot Type Conditioning (é•œå¤´ç±»å‹æ¡ä»¶æ§åˆ¶)
- åœ¨åŸå§‹çš„ text conditioning åŸºç¡€ä¸Šï¼Œå¢åŠ  **shot type embedding**
- Shot types ç¼–ç ä¸º learnable embeddingsï¼Œé€šè¿‡ FiLM æ³¨å…¥ç½‘ç»œ
- è¿™æ ·å¯ä»¥æ§åˆ¶ç”Ÿæˆçš„é•œå¤´æ„å›¾ç¬¦åˆç‰¹å®šç±»å‹ï¼ˆå¦‚è¿‘æ™¯äººç‰©æ›´å¤§ã€è¿œæ™¯äººç‰©æ›´å°ï¼‰

```python
# Shot type conditioning
shot_types = ['close-up', 'medium-shot', 'wide-shot', 'over-the-shoulder', 'two-shot']
shot_type_embedding = nn.Embedding(len(shot_types), embed_dim)

# Inject into FiLM alongside text and timestep
film_params = film_generator(text_embed + shot_type_embed + timestep_embed)
```

#### 2b. Inter-Shot Coherence (é•œå¤´é—´è¿è´¯æ€§)
- **ç©ºé—´è¿ç»­æ€§**: å‰ä¸€ä¸ªé•œå¤´çš„è§’è‰²å…¨å±€ä½ç½®ä½œä¸ºä¸‹ä¸€ä¸ªé•œå¤´çš„åˆå§‹åŒ–çº¦æŸ
- **180åº¦è§„åˆ™**: ç¡®ä¿æ‘„å½±æœºä¸è¶Šè¿‡ä¸¤ä¸ªè§’è‰²ä¹‹é—´çš„è½´çº¿
- **å®ç°æ–¹å¼**: åœ¨åå‘æ‰©æ•£è¿‡ç¨‹ä¸­åŠ å…¥ guidanceï¼š

```python
def coherence_guidance(prev_shot, current_noisy, t):
    """Guide denoising to maintain spatial coherence with previous shot"""
    # Soft constraint on character positions
    position_loss = mse(current_noisy.char_positions, prev_shot.char_positions)
    # 180-degree rule constraint
    angle_loss = axis_crossing_penalty(prev_shot.camera, current_noisy.camera)
    return gradient(position_loss + angle_loss)
```

### Module 3: Camera Motion Trajectory Generator (ğŸ†• æ ¸å¿ƒåˆ›æ–°æ¨¡å—)

**ç›®æ ‡**: å°†åŸè®ºæ–‡ç”Ÿæˆçš„é™æ€ Toric é•œå¤´ä½å§¿æ‰©å±•ä¸ºæ—¶åºä¸Šçš„é•œå¤´è¿åŠ¨è½¨è¿¹ã€‚

**æ ¸å¿ƒæ€è·¯**:
åŸè®ºæ–‡ç”Ÿæˆçš„æ˜¯å•ä¸€é™æ€é•œå¤´é…ç½® `x_C âˆˆ R^6`ï¼ˆToricå‚æ•°ï¼‰ï¼Œè¿™é‡Œå°†å…¶æ‰©å±•ä¸ºç”Ÿæˆ **T ä¸ªå…³é”®å¸§**ç»„æˆçš„æ—¶åºè½¨è¿¹ `X_C âˆˆ R^(KÃ—6)`ï¼Œå¹¶é€šè¿‡æ ·æ¡æ’å€¼å¾—åˆ°è¿ç»­å¹³æ»‘çš„é•œå¤´è¿åŠ¨è·¯å¾„ã€‚

**æ–¹æ³•**: ä¸¤é˜¶æ®µæ–¹æ¡ˆï¼ˆæ›´å¯æ§ã€æ›´ç¨³å®šï¼‰ï¼š

#### Stage 1: å…³é”®å¸§ç”Ÿæˆ (Keyframe Generation)
åŸºäºé•œå¤´è¿åŠ¨ç±»å‹å’Œæ–‡æœ¬æè¿°ï¼Œç”Ÿæˆ K ä¸ªå…³é”®å¸§çš„ Toric å‚æ•°ï¼š

```python
class CameraTrajectoryGenerator:
    """
    Generates camera motion trajectories from static shot configuration.
    
    Given:
    - Start Toric state x_C_start (from diffusion model)
    - Camera motion type (dolly-in, pan-left, etc.)
    - Duration T
    
    Produces: K keyframe Toric states â†’ smooth spline trajectory
    """
    
    # è¿åŠ¨ç±»å‹åˆ°Toricå‚æ•°å˜åŒ–çš„æ˜ å°„
    MOTION_PROFILES = {
        'static':     {'theta': 0, 'phi': 0, 'scale': 0},       # å›ºå®š
        'dolly-in':   {'theta': 0, 'phi': 0, 'scale': -0.3},    # æ¨è¿‘
        'dolly-out':  {'theta': 0, 'phi': 0, 'scale': +0.3},    # æ‹‰è¿œ
        'pan-left':   {'theta': -0.4, 'phi': 0, 'scale': 0},    # å·¦æ‘‡
        'pan-right':  {'theta': +0.4, 'phi': 0, 'scale': 0},    # å³æ‘‡
        'crane-up':   {'theta': 0, 'phi': +0.3, 'scale': 0},    # å‡
        'crane-down': {'theta': 0, 'phi': -0.3, 'scale': 0},    # é™
        'track':      {'theta': +0.2, 'phi': 0, 'scale': -0.1}, # è·Ÿè¸ª
    }
```

#### Stage 2: æ ·æ¡æ’å€¼ (Spline Interpolation)
å…³é”®å¸§ä¹‹é—´ç”¨ Catmull-Rom æ ·æ¡æ’å€¼ï¼Œç¡®ä¿è½¨è¿¹å¹³æ»‘ä¸”ä¸“ä¸šï¼š

```python
def interpolate_trajectory(keyframes, num_frames, method='catmull-rom'):
    """
    Interpolate between Toric keyframes to produce smooth trajectory.
    
    Args:
        keyframes: (K, 6) array of Toric keyframe states
        num_frames: Total number of output frames (T)
        method: Interpolation method
    
    Returns:
        trajectory: (T, 6) smooth camera trajectory in Toric space
    """
```

#### å¯é€‰è¿›é˜¶: å­¦ä¹ å‹è½¨è¿¹ç”Ÿæˆ (Learned Trajectory Generation)
å¦‚æœæ—¶é—´å…è®¸ï¼Œå¯ä»¥è®­ç»ƒä¸€ä¸ªå°å‹æ¡ä»¶æ‰©æ•£æ¨¡å‹ç›´æ¥ç”Ÿæˆè½¨è¿¹ï¼š
- è¾“å…¥ï¼šæ–‡æœ¬æè¿° + é•œå¤´è¿åŠ¨ç±»å‹ + è§’è‰²åŠ¨ä½œ
- è¾“å‡ºï¼š`X_C âˆˆ R^(TÃ—6)` æ—¶åºè½¨è¿¹
- å‚è€ƒï¼šDanceCamera3D (Wang et al., 2024) çš„é•œå¤´è½¨è¿¹ç”Ÿæˆæ¶æ„

### Module 4: Storyboard Renderer (æ–°å¢æ¨¡å—)

**ç›®æ ‡**: å°†ç”Ÿæˆçš„3Dé…ç½® + é•œå¤´è¿åŠ¨è½¨è¿¹æ¸²æŸ“ä¸º2Dæ•…äº‹æ¿é¢æ¿ã€‚

**æ–¹æ³•**:
1. **Stick Figure Rendering**: ä½¿ç”¨ matplotlib/Open3D å°† SMPL å…³èŠ‚ä½ç½®ç»˜åˆ¶ä¸ºç®€ç¬”ç”»äººç‰©
2. **Camera Framing**: æ ¹æ® Toric camera parameters ç¡®å®šç”»é¢è£å‰ªå’Œé€è§†
3. **Camera Path Overlay**: ğŸ†• åœ¨é¢æ¿ä¸Šå åŠ é•œå¤´è¿åŠ¨è½¨è¿¹è·¯å¾„ï¼ˆç®­å¤´ã€è¿åŠ¨æ–¹å‘ï¼‰
4. **Panel Layout**: å°†å¤šä¸ªé•œå¤´æ’åˆ—ä¸ºæ¼«ç”»å¼çš„æ•…äº‹æ¿å¸ƒå±€
5. **Annotation**: æ·»åŠ é•œå¤´ç¼–å·ã€æè¿°æ–‡å­—ã€é•œå¤´ç±»å‹ã€è¿åŠ¨ç±»å‹æ ‡æ³¨

```python
class StoryboardRenderer:
    def render_panel(self, char_a_pose, char_b_pose, camera_params, 
                     trajectory, shot_info):
        """Render a single storyboard panel with camera path overlay"""
        # 1. Transform poses to camera view
        # 2. Project 3D joints to 2D
        # 3. Draw stick figures
        # 4. Draw camera motion trajectory as arrow overlay
        # 5. Add frame border and annotations
        return panel_image
```

## 3. Data Pipeline

### è®­ç»ƒæ•°æ®
- **InterHuman Dataset**: åŒäººäº¤äº’åŠ¨ä½œæ•°æ®é›†ï¼ŒåŒ…å«æ–‡æœ¬æ ‡æ³¨
- **InterGen Dataset**: å¸¦æœ‰æ–‡æœ¬æè¿°çš„å¤šäººåŠ¨ä½œæ•°æ®
- **CineScale2**: é•œå¤´ç±»å‹æ ‡æ³¨ï¼ˆç”¨äº shot type conditioningï¼‰
- **Movie clip datasets**: MovieNet ç”¨äºå­¦ä¹ é•œå¤´åºåˆ—æ¨¡å¼
- **DanceCamera3D Dataset**: ğŸ†• é•œå¤´è¿åŠ¨è½¨è¿¹æ•°æ®ï¼ˆç”¨äºå­¦ä¹ å‹è½¨è¿¹ç”Ÿæˆï¼‰

### æ•°æ®å¤„ç†æµç¨‹
```
Raw Motion Data (BVH/SMPL) 
    â†’ SMPL Parameter Extraction (22 joints Ã— 6D rotation)
    â†’ Global Placement Vector Computation
    â†’ Toric Camera Parameter Computation
    â†’ Camera Motion Type Classification (if available)
    â†’ Text-Shot Pair Construction
    â†’ Training Data
```

## 4. Evaluation Plan

### å®šé‡æŒ‡æ ‡
| Metric | What it measures |
|--------|-----------------|
| FID (FrÃ©chet Inception Distance) | Quality of generated poses |
| Shot Type Accuracy | Whether generated camera matches target shot type |
| Spatial Coherence Score | Position consistency between consecutive shots |
| R-Precision | Text-motion alignment quality |
| Diversity Score | Variety of generated storyboards from same script |
| **Trajectory Smoothness** | ğŸ†• Jerk (ä¸‰é˜¶å¯¼æ•°) of camera trajectory |
| **Motion Type Accuracy** | ğŸ†• Whether trajectory matches requested motion type |
| **Trajectory-Action Consistency** | ğŸ†• How well camera motion follows character actions |

### å®šæ€§è¯„ä¼°
- **User Study**: è®©å½±è§†ä¸“ä¸šäººå£«è¯„ä»·æ•…äº‹æ¿çš„ä¸“ä¸šæ€§å’Œå¯ç”¨æ€§
- **Visual Comparison**: ä¸æ‰‹åŠ¨åˆ›å»ºçš„æ•…äº‹æ¿å¯¹æ¯”
- **Trajectory Visualization**: ğŸ†• å±•ç¤ºä¸åŒè¿åŠ¨ç±»å‹çš„è½¨è¿¹æ•ˆæœ
- **Ablation Visualization**: å±•ç¤ºå„æ¨¡å—çš„è´¡çŒ®

## 5. Technology Stack

| Component | Technology |
|-----------|------------|
| **Package Manager** | **uv** |
| Deep Learning Framework | PyTorch |
| Human Body Model | SMPL (smplx library) |
| Diffusion Model | Custom (based on MDM architecture) |
| Text Encoder | CLIP / Sentence-BERT |
| LLM for Shot Decomposition | OpenAI API / Local LLM (Llama) |
| Spline Interpolation | scipy.interpolate (CubicSpline / CatmullRom) |
| 3D Visualization | matplotlib 3D / Open3D / PyRender |
| Storyboard Rendering | Pillow / matplotlib |
| Experiment Tracking | Weights & Biases / TensorBoard |
| Version Control | Git + GitHub |

## 6. Key Innovation Points (åˆ›æ–°ç‚¹)

1. **é¦–ä¸ªä»å‰§æœ¬åˆ°å®Œæ•´æ•…äº‹æ¿çš„ç«¯åˆ°ç«¯ AI ç®¡çº¿** â€” å°†å•é•œå¤´ç”Ÿæˆæ‰©å±•ä¸ºå¤šé•œå¤´åºåˆ—
2. **é•œå¤´è¿åŠ¨è½¨è¿¹ç”Ÿæˆ** ğŸ†• â€” å°†é™æ€é•œå¤´ä½å§¿æ‰©å±•ä¸ºæ—¶åºç›¸æœºè½¨è¿¹ï¼ˆæ¨/æ‹‰/æ‘‡/ç§»/å‡/é™ï¼‰
3. **é•œå¤´ç±»å‹æ¡ä»¶æ§åˆ¶** â€” é€šè¿‡ shot type embedding å®ç°ç»†ç²’åº¦çš„æ‘„å½±æ„å›¾æ§åˆ¶
4. **é•œå¤´é—´è¿è´¯æ€§çº¦æŸ** â€” é€šè¿‡ guidance æœºåˆ¶ç¡®ä¿æ•…äº‹æ¿ç©ºé—´é€»è¾‘ä¸€è‡´
5. **å¯è§†åŒ–æ•…äº‹æ¿æ¸²æŸ“** â€” å°† 3D é…ç½® + è½¨è¿¹è‡ªåŠ¨è½¬åŒ–ä¸ºä¸“ä¸šçº§æ•…äº‹æ¿é¢æ¿ï¼ˆå«è¿åŠ¨è·¯å¾„æ ‡æ³¨ï¼‰

## 7. Scope Management (èŒƒå›´ç®¡ç†)

### Must Have (å¿…é¡»å®Œæˆ) â€” Week 1-6
- [ ] åŸºçº¿æ¨¡å‹å¤ç°
- [ ] Shot Decomposer æ¨¡å—
- [ ] å¤šé•œå¤´åºåˆ—ç”Ÿæˆ
- [ ] **åŸºäºè§„åˆ™çš„é•œå¤´è¿åŠ¨è½¨è¿¹ç”Ÿæˆï¼ˆå…³é”®å¸§ + æ ·æ¡æ’å€¼ï¼‰**
- [ ] åŸºç¡€æ•…äº‹æ¿å¯è§†åŒ–ï¼ˆå«è½¨è¿¹è·¯å¾„æ ‡æ³¨ï¼‰
- [ ] å®šé‡è¯„ä¼°

### Should Have (åº”è¯¥å®Œæˆ) â€” Week 7-8
- [ ] Shot type conditioning
- [ ] Inter-shot coherence guidance
- [ ] Professional storyboard panel rendering
- [ ] **å¤šç§é•œå¤´è¿åŠ¨ç±»å‹æ”¯æŒï¼ˆæ¨/æ‹‰/æ‘‡/ç§»/å‡/é™/è·Ÿè¸ªï¼‰**

### Nice to Have (é”¦ä¸Šæ·»èŠ±) â€” ä»…æ—¶é—´å……è£•æ—¶
- [ ] **å­¦ä¹ å‹è½¨è¿¹ç”Ÿæˆï¼ˆæ¡ä»¶æ‰©æ•£æ¨¡å‹ï¼‰**
- [ ] Interactive web demo (Gradio/Streamlit)
- [ ] è½¨è¿¹3Då¯è§†åŒ–åŠ¨ç”»
- [ ] Video generation from storyboard
